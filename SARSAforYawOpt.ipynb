{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Dec  2 16:00:40 2019\n",
    "\n",
    "@author: sanja\n",
    "\"\"\"\n",
    "\n",
    "''\n",
    "import gym\n",
    "import numpy as np\n",
    "from scipy.integrate import ode\n",
    "import numpy.random as rnd\n",
    "import torch as pt\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "import environment\n",
    "import floris.tools as wfct\n",
    "\n",
    "\n",
    "class nnQ(pt.nn.Module):\n",
    "    \"\"\"\n",
    "    Here is a basic neural network with for representing a policy \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,stateDim,numActions,numHiddenUnits,numLayers):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        InputLayer = [pt.nn.Linear(stateDim+numActions,numHiddenUnits),\n",
    "                      pt.nn.Sigmoid()]\n",
    "        \n",
    "        HiddenLayers = []\n",
    "        \n",
    "        for _ in range(numLayers-1):\n",
    "            HiddenLayers.append(pt.nn.Linear(numHiddenUnits,numHiddenUnits))\n",
    "            HiddenLayers.append(pt.nn.ReLU())\n",
    "            \n",
    "        OutputLayer = [pt.nn.Linear(numHiddenUnits,1)]\n",
    "        \n",
    "        AllLayers = InputLayer + HiddenLayers + OutputLayer\n",
    "        self.net = pt.nn.Sequential(*AllLayers)\n",
    "        \n",
    "        self.numActions = numActions\n",
    "        \n",
    "    def forward(self,x,a):\n",
    "        x = pt.tensor(x,dtype=pt.float32) # feature\n",
    "        a = pt.tensor(a, dtype=pt.int64)  # parametesw\n",
    "        b = pt.nn.functional.one_hot(a,self.numActions)\n",
    "        c = b.float().detach()\n",
    "        y = pt.cat([x,c])\n",
    "        \n",
    "        return self.net(y)\n",
    "        \n",
    "    \n",
    "class sarsaAgent:\n",
    "    def __init__(self,stateDim ,numActions,numHiddenUnits,numLayers,\n",
    "                epsilon=0.1,gamma=.9,alpha=.1):\n",
    "        # These are the parameters\n",
    "        self.Q = nnQ(stateDim,numActions,numHiddenUnits,numLayers)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.numActions = numActions\n",
    "        self.s_last = None\n",
    "    \n",
    "    \n",
    "    # The action is chosen acc to eps-greedy    \n",
    "    def action(self,x):\n",
    "        # This is an epsilon greedy selection (can do max also)\n",
    "        # Whichever has the highest Q, perform that action\n",
    "        if rnd.rand() < self.epsilon:\n",
    "            a = rnd.randint(numActions)\n",
    "        else:\n",
    "            qBest = -np.inf\n",
    "            a = rnd.randint(numActions)\n",
    "            for aTest in range(self.numActions):\n",
    "                qTest = self.Q(x,aTest).detach().numpy()[0]\n",
    "                if qTest > qBest:\n",
    "                    qBest = qTest\n",
    "                    a = aTest\n",
    "        return a\n",
    "    \n",
    "    def update(self,s,a,r,s_next,done):\n",
    "        \n",
    "        # Compute the TD error, if there is enough data\n",
    "        update = True\n",
    "        if done:\n",
    "            Q_cur = self.Q(s,a).detach().numpy()[0]\n",
    "            delta = r - Q_cur\n",
    "            self.s_last = None\n",
    "            Q_diff = self.Q(s,a)\n",
    "        elif self.s_last is not None:\n",
    "            Q_next = self.Q(s,a).detach().numpy()[0]\n",
    "            Q_cur = self.Q(self.s_last,self.a_last).detach().numpy()[0]\n",
    "            delta = self.r_last + self.gamma * Q_next - Q_cur\n",
    "            Q_diff = self.Q(self.s_last,self.a_last)\n",
    "        else:\n",
    "            update = False\n",
    "            \n",
    "        # Update the parameter via the semi-gradient method\n",
    "        if update:\n",
    "            self.Q.zero_grad()\n",
    "            Q_diff.backward()\n",
    "            for p in self.Q.parameters():\n",
    "                p.data.add_(self.alpha*delta,p.grad.data)\n",
    "            \n",
    "            \n",
    "        \n",
    "        if not done:\n",
    "            self.s_last = np.copy(s)\n",
    "            self.a_last = np.copy(a)\n",
    "            self.r_last = np.copy(r)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5358102.420735784\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "2698936.509642075\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "3287744.4897210817\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "5358102.420735784\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6140186.966637169\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "6194778.385243995\n",
      "Episode: 1 Total Steps: 100 , Ave. Reward/Power : 6194778.385243995 , Episode Length: 100\n"
     ]
    }
   ],
   "source": [
    "            \n",
    "# This is the environment\n",
    "#env = swingUp.SwingUpEnv()\n",
    "\n",
    "# Let us consider that \n",
    "nTurb = 2;\n",
    "numActions = 10;\n",
    "Actions = np.linspace(0,50,numActions)\n",
    "\n",
    "# This is our learning agent\n",
    "gamma = .95\n",
    "agent = sarsaAgent(nTurb,numActions,10,1,epsilon=5e-2,gamma=gamma,alpha=1e-2)\n",
    "maxSteps = 1e2\n",
    "\n",
    "R = []\n",
    "UpTime = []\n",
    "\n",
    "step = 0\n",
    "ep = 0\n",
    "fi = wfct.floris_interface.FlorisInterface(\"./example_input.json\")\n",
    "fi.calculate_wake()\n",
    "\n",
    "while step < maxSteps:\n",
    "    ep += 1\n",
    "    x = environment.reset(nTurb) # initialize the state\n",
    "    C = 0.  \n",
    "    \n",
    "    done = False\n",
    "    t = 1\n",
    "    while not done:\n",
    "        t += 1 \n",
    "        step += 1\n",
    "        a = agent.action(x)\n",
    "        u = Actions[a];\n",
    "    \n",
    "        x_next,c, done = environment.step(u,x,fi)\n",
    "        print(c)\n",
    "        C += (1./t)*(c-C)\n",
    "        agent.update(x,a,c,x_next,done)\n",
    "        x = x_next\n",
    "         \n",
    "\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "        if step >= maxSteps:\n",
    "            break\n",
    "            \n",
    "        \n",
    "        R.append(C)\n",
    "        \n",
    "    print('Episode:',ep,'Total Steps:',step,', Ave. Reward/Power :',c,', Episode Length:',t-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5833.333333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "70000/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2916.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5833/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
